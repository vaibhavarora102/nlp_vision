{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook covers\n",
    "- building own model for word2vec\n",
    "- pca model\n",
    "- using embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What TV shows or books help you read people's body language?\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = list(open(\"./resources/quora.txt\", encoding=\"utf-8\"))\n",
    "data1[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'TV', 'shows', 'or', 'books', 'help', 'you', 'read', 'people', \"'\", 's', 'body', 'language', '?']\n"
     ]
    }
   ],
   "source": [
    "#  tokenization\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "print(tokenizer.tokenize(data1[50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text =text.lower()\n",
    "    split=tokenizer.tokenize(text)\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tok = []\n",
    "\n",
    "for i in data1:\n",
    "    data_tok.append(tokenize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'are',\n",
       " 'some',\n",
       " 'ways',\n",
       " 'to',\n",
       " 'overcome',\n",
       " 'a',\n",
       " 'fast',\n",
       " 'food',\n",
       " 'addiction',\n",
       " '?']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tok[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"can i get back with my ex even though she is pregnant with another guy ' s baby ?\", 'what are some ways to overcome a fast food addiction ?', 'who were the great chinese soldiers and leaders who fought in ww2 ?', 'what are zip codes in the bay area ?', 'why was george rr martin critical of jk rowling after losing the hugo award ?', 'what can i do to improve my immune system ?', 'how is your relationship with your mother in law ?']\n"
     ]
    }
   ],
   "source": [
    "print([' '.join(row) for row in data_tok[:7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word to vector conversion\n",
    "model = Word2Vec(data_tok,\n",
    "                  size=32,\n",
    "                  min_count=5,\n",
    "                  window=5).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09853829,  1.6637228 ,  0.41568366, -0.00701518, -0.3391021 ,\n",
       "        0.30230296,  0.2509836 ,  0.11918498, -0.21415508,  0.95404977,\n",
       "       -1.0878644 ,  0.7662037 ,  0.21060596,  1.088231  ,  0.13110164,\n",
       "        0.08940145, -0.05772331,  0.13463493, -0.38112   , -0.5951496 ,\n",
       "        0.4222265 ,  2.350488  ,  0.37412882, -1.8292218 ,  1.4630253 ,\n",
       "        0.15652086,  0.4987727 ,  1.0553471 , -0.8946765 ,  0.7793316 ,\n",
       "       -0.67696506,  0.09309817], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  to get vector of word\n",
    "\n",
    "model.get_vector('addiction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('working', 0.7293875217437744),\n",
       " ('switch', 0.7216125130653381),\n",
       " ('perform', 0.6980670690536499),\n",
       " ('look', 0.6749083995819092),\n",
       " ('move', 0.6709790825843811),\n",
       " ('hire', 0.6589975357055664),\n",
       " ('offer', 0.6489494442939758),\n",
       " ('compete', 0.6482181549072266),\n",
       " ('live', 0.6462299227714539),\n",
       " ('go', 0.6365026235580444)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query of similar words directly\n",
    "model.most_similar('work')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "model =api.load('glove-twitter-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('broker', 0.5820155739784241),\n",
       " ('bonuses', 0.5424473285675049),\n",
       " ('banker', 0.538511335849762),\n",
       " ('designer', 0.5197198390960693),\n",
       " ('merchandising', 0.4964233934879303),\n",
       " ('treet', 0.49220192432403564),\n",
       " ('shopper', 0.4920561909675598),\n",
       " ('part-time', 0.49128279089927673),\n",
       " ('freelance', 0.4843311905860901),\n",
       " ('aupair', 0.4796452522277832)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"coder\", \"money\"], negative=[\"brain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<user>', 'can', 'al', 'ØŸ', 'fucking', 'kau', 'eres', 'dong', 'sad', 'eyes']\n"
     ]
    }
   ],
   "source": [
    "words = sorted(model.vocab.keys(), \n",
    "               key=lambda word: model.vocab[word].count,\n",
    "               reverse=True)[:1000]\n",
    "\n",
    "print(words[::102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute vector with model\n",
    "word_vectors = []\n",
    "\n",
    "for i in words:\n",
    "    word_vectors.append(model.get_vector(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = np.array(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, random_state=2018)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "word_vectors_pca = pca.fit_transform(word_vectors)\n",
    "word_vectors_pca = scaler.fit_transform(word_vectors_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
